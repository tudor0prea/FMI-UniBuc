
import pandas as pd
import numpy as np
import os
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

def add_extension(x):
    x = x + ".png"
    return x

# Citim fișierul CSV și încărcăm imaginile corespunzătoare
df = pd.read_csv('/kaggle/input/unibuc-brain-ad/data/train_labels.txt',dtype=str)
#df['id'] = df['id'].astype(str)
df['id'] = df['id'].apply(add_extension)
df['class'] = df['class'].astype(str)
# Definim un obiect ImageDataGenerator pentru a prelucra imaginile și a le încărca în model
datagen = keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255
)

# Folosim flow_from_dataframe pentru a încărca datele din fișierul CSV
train_data = datagen.flow_from_dataframe(
    dataframe=df,
    directory='/kaggle/input/unibuc-brain-ad/data/data',
    x_col='id',
    y_col='class',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Definim arhitectura modelului CNN
model = Sequential([
    layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2,2)),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

# Compilam modelul cu o functie de pierdere si un algoritm de optimizare
model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# Antrenam modelul pe datele de antrenament și validare
model.fit(
    train_data,
    epochs=10
)

# Salvam modelul antrenat,0
model.save('tomography_classification_model.h5')









// -----------------------------------------


import pandas as pd
import numpy as np
import os
import csv
import re
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential


input_csv_name = '/kaggle/input/unibuc-brain-ad/data/sample_submission.txt'
dir_path = "/kaggle/input/unibuc-brain-ad/data/data"
model_path = '/kaggle/input/model-si-csv/tomography_classification_model.h5'
output_csv = 'sample_submission_new0.txt'

def add_extension(x):
    x = x + ".png"
    return x


def get_class(predictions):
    class_labels = [True, False]
    predicted_class_indices = np.argmax(predictions, axis=1)
    return [class_labels[predicted_class_indices[i]] for i in range(len(predicted_class_indices))]



# Citim fișierul CSV și încărcăm imaginile corespunzătoare

df = pd.read_csv(input_csv_name,dtype=str)
df['id'] = df['id'].apply(add_extension)


# Definim un obiect ImageDataGenerator pentru a prelucra imaginile și a le încărca în model
datagen = keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255
)

# Folosim flow_from_dataframe pentru a încărca datele din fișierul CSV
test_generator = datagen.flow_from_dataframe(
    dataframe=df,
    directory=dir_path,
    x_col='id',
    target_size=(224, 224),
    batch_size=1,
    shuffle=False,
    class_mode=None
)
# Incarcam modelul antrenat
model = keras.models.load_model(model_path)

# Generam predicțiile modelului pe datele noi
predictions = model.predict(test_generator)

lst = []
for i in range(len(predictions)):
        if predictions[i][0]<0.5:
             lst.append(0)
        else:
             lst.append(1)






# Salvam predicțiile într-un fișier CSV
df_predictions = pd.DataFrame({'id': df['id'], 'class': lst})
df_predictions.to_csv(output_csv, index=False)


// --------------------------------------------------------------------------------------



with open("/kaggle/working/sample_submission_new0.txt", "r") as f1, open("output_subm2.csv", "w") as f2:
    f2.write("id,class\n")
    next(f1) # skip header line
    for line in f1:
        line = line.strip().split(",")
        id = line[0].replace(".png", "")
        clasa = True if line[1] == "1" else False
        f2.write("{},{}\n".format(id, clasa))
